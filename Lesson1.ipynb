{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST dataset\n",
    "# MNIST dataset has a shape of (70000, 784) meaning there are 70,000 images with 784 dimensions (784 features).\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = mnist.data[4].reshape((28,28))\n",
    "label =  mnist.target[4]\n",
    "\n",
    "plt.figure(figsize = (15,2))\n",
    "imgplot = plt.imshow(image,cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(\"Label:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mnist.data = np.reshape(mnist.data,(-1,28,28,1))\n",
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size: what proportion of original data is used for test set\n",
    "train_img, test_img, train_lbl, test_lbl = train_test_split( mnist.data, mnist.target, test_size=1/7.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to one-hot vector\n",
    "#For example, label '0' => [1,0,0,0,0,0,0,0,0,0,0], '1' => [0,1,0,0,0,0,0,0,0,0,0], ...\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_lbl = to_categorical(train_lbl)\n",
    "test_lbl = to_categorical(test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "input_layer = Input(shape=(28,28,1))\n",
    "conv_layer = Conv2D(50,(3,3),activation=\"relu\",padding=\"same\")(input_layer)\n",
    "pooling_layer = MaxPooling2D((2,2))(conv_layer)\n",
    "flatten_layer = Flatten()(pooling_layer)\n",
    "dense_layer2 = Dense(10, activation=\"softmax\")(flatten_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=dense_layer2)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(train_img,train_lbl,validation_data=(test_img,test_lbl), epochs= 10, batch_size=2000,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5\")\n",
    "model.save(\"model.h5\",include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(28,28,1))\n",
    "conv_layer = Conv2D(50,(3,3),activation=\"relu\",padding=\"same\")(input_layer)\n",
    "pooling_layer = MaxPooling2D((2,2))(conv_layer)\n",
    "flatten_layer = Flatten()(pooling_layer)\n",
    "dense_layer2 = Dense(10, activation=\"softmax\")(flatten_layer)\n",
    "\n",
    "saved_model = Model(inputs=input_layer, outputs=dense_layer2)\n",
    "\n",
    "saved_model.load_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('model.h5')\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
