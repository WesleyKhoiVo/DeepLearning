{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WesleyKhoiVo/DeepLearning/blob/main/Lesson2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fikuBlNeeLyJ"
      },
      "outputs": [],
      "source": [
        "#Load MNIST dataset\n",
        "# MNIST dataset has a shape of (70000, 784) meaning there are 70,000 images with 784 dimensions (784 features).\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(\"mnist_784\", as_frame=False, parser='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kiasXwOeeLyU",
        "outputId": "27d8e703-e68b-4f54-90e1-88e1dc5c2de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# test_size: what proportion of original data is used for test set\n",
        "train_img, test_img, train_lbl, test_lbl = train_test_split( mnist.data, mnist.target, test_size=1/7.0, random_state=0)\n",
        "train_lbl[0:10]\n",
        "train_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KVbFkCF8eLyX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_lbl = np.array([int(x) for x in train_lbl],dtype=int)\n",
        "test_lbl = np.array([int(x) for x in test_lbl],dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rYH7UqnkeLyZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TwoLayerNet(nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        \"\"\"\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, H)\n",
        "        self.linear2 = nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        h_sigmoid  = F.sigmoid(self.linear1(x))\n",
        "        y_pred = self.linear2(h_sigmoid)\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "usku7S8NeLyb",
        "outputId": "c5a9cbc1-dbbd-4543-b48c-8e319fde846d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd7b141e2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "N, D_in, H, D_out = 20, 784, 10, 10\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "train_img = torch.Tensor(train_img)\n",
        "train_lbl = torch.Tensor(train_lbl).type(torch.LongTensor)\n",
        "train_dataset = TensorDataset(train_img,train_lbl)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=False)\n",
        "train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g_9H_B2JeLyc",
        "outputId": "9df0fb73-2056-437e-fd76-8e4e0db2804e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.879\n",
            "[1,  4000] loss: 1.389\n",
            "[1,  6000] loss: 1.190\n",
            "[2,  2000] loss: 1.081\n",
            "[2,  4000] loss: 0.955\n",
            "[2,  6000] loss: 0.896\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ARSV1sFueLye",
        "outputId": "9acbfe56-e560-409c-cfe0-2ae078093a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8, 4, 1,  ..., 1, 3, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#predict \n",
        "test_img = torch.Tensor(test_img)\n",
        "outputs = model(test_img)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "predicted"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}